services:
  db:
    image: postgres:15-alpine
    restart: always
    env_file:
      - .env
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=cadence_ai
    ports:
      - '5432:5432'
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d cadence_ai"]
      interval: 5s
      timeout: 5s
      retries: 5

  backend:
    build: ./backend
    ports:
      - "8000:8000"
    env_file:
      - .env
      - ./backend/.env
    environment:
      - DATABASE_URL=postgresql+asyncpg://postgres:postgres@db:5432/cadence_ai
      - OLLAMA_BASE_URL=http://ollama:11434
      - AI_WORKER_URL=http://ai_worker:8001
      - LLM_MODEL=qwen2.5:0.5b
      - FRONTEND_URL=http://localhost:3000
      - OAUTH_REDIRECT_BASE=http://localhost:8000/api/v1/social/callback
    volumes:
      - ./backend:/app
    restart: always
    depends_on:
      db:
        condition: service_healthy

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    env_file:
      - .env
    environment:
      - NODE_ENV=development
      - NEXT_PUBLIC_API_URL=http://localhost:8000/api
      - INTERNAL_API_URL=http://backend:8000
    volumes:
      - /app/node_modules
    user: root
    restart: always
    depends_on:
      - backend

  adminer:
    image: adminer
    restart: always
    ports:
      - 8080:8080

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    restart: always

  ai_worker:
    build: ./ai_worker
    ports:
      - "8001:8001"
    env_file:
      - .env
      - ./backend/.env
    restart: always

volumes:
  postgres_data:
  ollama_models:
